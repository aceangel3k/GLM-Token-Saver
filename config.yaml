models:
  local:
    enabled: true
    name: "GLM-4.7-Flash"
    endpoint: "http://spark0.tail1f104f.ts.net:41447/v1/chat/completions"
    api_key: ""
    model: "unsloth_GLM-4.7-Flash-GGUF_GLM-4.7-Flash-Q4_K_M"
    context_length: 200000
    max_tokens: 4096
    timeout: 120
  
  cerebras:
    enabled: true
    name: "Cerebras GLM 4.7"
    endpoint: "https://api.cerebras.ai/v1/chat/completions"
    api_key: "csk-dvw9xey5x23mkccp629h8j5cpk6p29vhctvm96cf649kvjck"
    model: "glm-4.7-355b"
    context_length: 131000
    max_tokens: 4096
    timeout: 120

routing:
  strategy: "smart_routing"  # Options: smart_routing, speculative_decoding, always_local, always_cerebras
  simple_task_threshold: 1000  # tokens
  complexity_keywords:
    - "code"
    - "debug"
    - "architecture"
    - "optimize"
    - "refactor"
    - "implement"
    - "algorithm"
    - "complex"
    - "difficult"
    - "challenging"
  
speculative_decoding:
  enabled: true
  draft_model: "local"
  verify_model: "cerebras"
  max_draft_tokens: 10
  min_confidence: 0.8
  
cost_tracking:
  budget_limit: 100.0  # USD
  alert_threshold: 80.0
  cerebras_cost_per_1k_tokens: 0.002  # Adjust based on actual pricing
  
server:
  host: "0.0.0.0"
  port: 8000
  log_level: "info"
  
logging:
  file: "logs/api_server.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5
