models:
  local:
    enabled: true
    name: "GLM-4.7-Flash"
    endpoint: "http://your-local-endpoint:41447/v1/chat/completions"
    api_key: "YOUR_API_KEY_HERE"
    model: "unsloth/GLM-4.7-Flash-GGUF"
    context_length: 64000
    max_tokens: 4096
    timeout: 120
  
  cerebras:
    enabled: true
    name: "Cerebras GLM 4.7"
    endpoint: "https://api.cerebras.ai/v1/chat/completions"
    api_key: "YOUR_CEREBRAS_API_KEY_HERE"
    model: "zai-glm-4.7"
    context_length: 131000
    max_tokens: 4096
    timeout: 120

routing:
  strategy: "speculative_decoding"  # Options: smart_routing, speculative_decoding, always_local, always_cerebras
  simple_task_threshold: 1000  # tokens
  complexity_keywords:
    - "code"
    - "debug"
    - "architecture"
    - "optimize"
    - "refactor"
    - "implement"
    - "algorithm"
    - "complex"
    - "difficult"
    - "challenging"
  
speculative_decoding:
  enabled: true
  draft_model: "local"
  verify_model: "cerebras"
  max_draft_tokens: 10
  min_confidence: 0.8
  
cost_tracking:
  budget_limit: 100.0  # USD
  alert_threshold: 80.0
  cerebras_cost_per_1k_tokens: 0.002  # Adjust based on actual pricing
  
server:
  host: "0.0.0.0"
  port: 8000
  log_level: "info"  # Log info, warnings, and errors
  
logging:
  file: "logs/api_server.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5